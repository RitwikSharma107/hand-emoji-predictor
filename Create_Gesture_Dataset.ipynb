{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Width and Height of image\n",
    "image_x, image_y = 50, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create folder for each gesture\n",
    "def create_folder(folder_name):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.mkdir(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "fbag = cv2.createBackgroundSubtractorMOG2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to store gestures        \n",
    "def main(g_id):\n",
    "    #Max pics of gesture allowed\n",
    "    total_pics = 500\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    #Particular area of capturing gesture\n",
    "    x, y, w, h = 300, 50, 350, 350\n",
    "\n",
    "    create_folder(\"Gestures/\" + str(g_id))\n",
    "    pic_no = 0\n",
    "    flag_start_capturing = False\n",
    "    frames = 0\n",
    "\n",
    "    while True:\n",
    "        #Read frame from webcam\n",
    "        ret, frame = cap.read()\n",
    "        #Flip the read frame to get correct orientation\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        #Convert to HSV Format\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        #THRESH SCREEN\n",
    "        #Set mask in range of skin color\n",
    "        mask2 = cv2.inRange(hsv, np.array([2, 50, 60]), np.array([25, 150, 255]))\n",
    "        res = cv2.bitwise_and(frame, frame, mask=mask2)\n",
    "        #Convert to grey scale\n",
    "        gray = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)\n",
    "        median = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "        #Initialize kernel\n",
    "        kernel_square = np.ones((5, 5), np.uint8)\n",
    "        #Improve the quality of captured gesture\n",
    "        dilation = cv2.dilate(median, kernel_square, iterations=2)\n",
    "        opening=cv2.morphologyEx(dilation,cv2.MORPH_CLOSE,kernel_square)\n",
    "\n",
    "        ret, thresh = cv2.threshold(opening, 30, 255, cv2.THRESH_BINARY)\n",
    "        #Set thresh according to particular area\n",
    "        thresh = thresh[y:y + h, x:x + w]\n",
    "        #Find cotours in thresh\n",
    "        contours = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)[0]\n",
    "\n",
    "        #IF contours exixts\n",
    "        if len(contours) > 0:\n",
    "            contour = max(contours, key=cv2.contourArea)\n",
    "            #Condition for starting the process of capturing gesture\n",
    "            if cv2.contourArea(contour) > 10000 and frames > 50:\n",
    "                x1, y1, w1, h1 = cv2.boundingRect(contour)\n",
    "                pic_no += 1\n",
    "                save_img = thresh[y1:y1 + h1, x1:x1 + w1]\n",
    "                if w1 > h1:\n",
    "                    save_img = cv2.copyMakeBorder(save_img, int((w1 - h1) / 2), int((w1 - h1) / 2), 0, 0,\n",
    "                                                  cv2.BORDER_CONSTANT, (0, 0, 0))\n",
    "                elif h1 > w1:\n",
    "                    save_img = cv2.copyMakeBorder(save_img, 0, 0, int((h1 - w1) / 2), int((h1 - w1) / 2),\n",
    "                                                  cv2.BORDER_CONSTANT, (0, 0, 0))\n",
    "                save_img = cv2.resize(save_img, (image_x, image_y))\n",
    "                cv2.putText(frame, \"Capturing...\", (30, 60), cv2.FONT_HERSHEY_TRIPLEX, 2, (127, 255, 255))\n",
    "                cv2.imwrite(\"Gestures/\" + str(g_id) + \"/\" + str(pic_no) + \".jpg\", save_img)\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, str(pic_no), (30, 400), cv2.FONT_HERSHEY_TRIPLEX, 1.5, (127, 127, 255))\n",
    "        #FRAME SCREEN Heading\n",
    "        cv2.imshow(\"Capturing gesture\", frame)\n",
    "        #THRESH SCREEN Heading\n",
    "        cv2.imshow(\"thresh\", thresh)\n",
    "        #Start the process when 'c' is pressed\n",
    "        keypress = cv2.waitKey(1)\n",
    "        if keypress == ord('c'):\n",
    "            if flag_start_capturing == False:\n",
    "                flag_start_capturing = True\n",
    "            else:\n",
    "                flag_start_capturing = False\n",
    "                frames = 0\n",
    "        if flag_start_capturing == True:\n",
    "            frames += 1\n",
    "        if pic_no == total_pics:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter gesture number: 20\n"
     ]
    }
   ],
   "source": [
    "g_id = input(\"Enter gesture number: \")\n",
    "main(g_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
